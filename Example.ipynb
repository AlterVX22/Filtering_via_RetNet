{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27afca67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!git clone https://github.com/AlterVX22/Filtering_via_RetNet.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6025729",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"Collab-filtering-via-RetNet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e35157ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "from torchscale.architecture.config import RetNetConfig\n",
    "from torchscale.architecture.retnet import RetNetDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5082b5b",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# location of datasets: https://www.kaggle.com/datasets/vxmindset22/okko-data\n",
    "with open('datasets.pkl', 'rb') as f:\n",
    "    datasets = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87b97710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': (         userId  movieId\n",
       "  1926171  185543     2016\n",
       "  1926172   50933     3284\n",
       "  1926173  230764       68\n",
       "  1926174  186260     1473\n",
       "  1926175   94969      493\n",
       "  ...         ...      ...\n",
       "  9630848  479013     3766\n",
       "  9630849   29856      876\n",
       "  9630850  277832     4771\n",
       "  9630851   77545      491\n",
       "  9630852  260632     6147\n",
       "  \n",
       "  [7704682 rows x 2 columns],\n",
       "  1926171    0.189311\n",
       "  1926172    0.390769\n",
       "  1926173    0.010635\n",
       "  1926174    0.102065\n",
       "  1926175    0.200385\n",
       "               ...   \n",
       "  9630848    0.089422\n",
       "  9630849    0.200385\n",
       "  9630850    0.176240\n",
       "  9630851    0.190627\n",
       "  9630852    0.200385\n",
       "  Name: rating_scaled, Length: 7704682, dtype: float64),\n",
       " 'test': (         userId  movieId\n",
       "  0             0        0\n",
       "  1             1        1\n",
       "  2             2        2\n",
       "  3             3        3\n",
       "  4             4        4\n",
       "  ...         ...      ...\n",
       "  1926166  236143      587\n",
       "  1926167  120603      130\n",
       "  1926168   56511      245\n",
       "  1926169  149668      493\n",
       "  1926170  215417      302\n",
       "  \n",
       "  [1926171 rows x 2 columns],\n",
       "  0          0.541737\n",
       "  1          0.199687\n",
       "  2          0.036432\n",
       "  3          0.090279\n",
       "  4          0.390769\n",
       "               ...   \n",
       "  1926166    0.200385\n",
       "  1926167    0.072087\n",
       "  1926168    0.200385\n",
       "  1926169    0.162837\n",
       "  1926170    0.010894\n",
       "  Name: rating_scaled, Length: 1926171, dtype: float64)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ff502c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = datasets['train'][0]\n",
    "X_test = datasets['test'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb310d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_users = pd.concat([X_train[\"userId\"], X_test[\"userId\"]])\n",
    "user_count = combined_users.nunique()\n",
    "\n",
    "combined_movie = pd.concat([X_train[\"movieId\"], X_test[\"movieId\"]])\n",
    "movie_count = combined_movie.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9cc84c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "retnet_config = RetNetConfig(vocab_size = 200,\n",
    "                             decoder_layers=8,\n",
    "                             decoder_embed_dim=200,\n",
    "                             decoder_value_embed_dim=200,\n",
    "                             decoder_retention_heads=4,\n",
    "                             decoder_ffn_embed_dim=200,\n",
    "                             chunkwise_recurrent = False\n",
    "                                 )\n",
    "\n",
    "\n",
    "batch_size = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e01b184f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSELoss(nn.Module):\n",
    "    def __init__(self, reduction='sum'):\n",
    "        super(RMSELoss, self).__init__()\n",
    "        self.mse = nn.MSELoss(reduction=reduction)\n",
    "        \n",
    "    def forward(self, y_pred, y_true):\n",
    "        loss = torch.sqrt(self.mse(y_pred, y_true))\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9cb5288c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea3292b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from filteringRetNet import DatasetBatchIterator\n",
    "from filteringRetNet import NeuralColabFilteringRetNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2cb14073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop control parameters\n",
    "max_epochs = 1\n",
    "early_stop_epoch_threshold = 3\n",
    "no_loss_reduction_epoch_counter = 0\n",
    "min_loss = np.inf\n",
    "min_loss_model_weights = None\n",
    "history = []\n",
    "\n",
    "ncf_retnet = NeuralColabFilteringRetNet(user_count, \n",
    "                                        movie_count, \n",
    "                                        retnet_config,\n",
    "                                        hidden_size = retnet_config.decoder_embed_dim,\n",
    "                                        device = device).to(device)\n",
    "\n",
    "\n",
    "\n",
    "loss_criterion = RMSELoss(reduction='sum').to(device)\n",
    "#loss_criterion_2 = nn.L1Loss(reduction='sum').to(device)\n",
    "optimizer = optim.Adam(ncf_retnet.parameters(), lr=1e-3, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39900d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2bb0ac22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train phase:   1%|â–Œ                                                                  | 3/385 [00:31<1:06:31, 10.45s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# We need to compute gradients only during training\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(is_training):\n\u001b[1;32m---> 24\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m ncf_retnet(x_batch[:, \u001b[38;5;241m0\u001b[39m], x_batch[:, \u001b[38;5;241m1\u001b[39m], )\n\u001b[0;32m     25\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_criterion(outputs, y_batch)\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;66;03m#loss_2 = loss_criterion_2(outputs, y_batch)\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\Collab-filtering-via-RetNet\\filteringRetNet.py:60\u001b[0m, in \u001b[0;36mNeuralColabFilteringRetNet.forward\u001b[1;34m(self, user_ids, movie_ids)\u001b[0m\n\u001b[0;32m     57\u001b[0m embedding \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mEmbedding(\u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_count \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmovie_count \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m     58\u001b[0m inputs_embeds \u001b[38;5;241m=\u001b[39m embedding(input_ids)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m---> 60\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretnet_model(prev_output_tokens\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m     61\u001b[0m                             token_embeddings\u001b[38;5;241m=\u001b[39minputs_embeds)\n\u001b[0;32m     63\u001b[0m last_hidden_state \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m][:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]\n\u001b[0;32m     64\u001b[0m linear_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear(last_hidden_state)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torchscale\\architecture\\retnet.py:366\u001b[0m, in \u001b[0;36mRetNetDecoder.forward\u001b[1;34m(self, prev_output_tokens, incremental_state, features_only, return_all_hiddens, token_embeddings, **kwargs)\u001b[0m\n\u001b[0;32m    363\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m idx \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m incremental_state:\n\u001b[0;32m    364\u001b[0m         incremental_state[idx] \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 366\u001b[0m x, l_aux_i \u001b[38;5;241m=\u001b[39m layer(\n\u001b[0;32m    367\u001b[0m     x,\n\u001b[0;32m    368\u001b[0m     incremental_state[idx] \u001b[38;5;28;01mif\u001b[39;00m incremental_state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    369\u001b[0m     retention_rel_pos\u001b[38;5;241m=\u001b[39mretention_rel_pos,\n\u001b[0;32m    370\u001b[0m     chunkwise_recurrent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunkwise_recurrent,\n\u001b[0;32m    371\u001b[0m )\n\u001b[0;32m    372\u001b[0m l_aux\u001b[38;5;241m.\u001b[39mappend(l_aux_i)\n\u001b[0;32m    373\u001b[0m inner_states\u001b[38;5;241m.\u001b[39mappend(x)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torchscale\\architecture\\retnet.py:165\u001b[0m, in \u001b[0;36mDecoderLayer.forward\u001b[1;34m(self, x, incremental_state, chunkwise_recurrent, retention_rel_pos)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalize_before:\n\u001b[0;32m    163\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretention_layer_norm(x)\n\u001b[1;32m--> 165\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretention(\n\u001b[0;32m    166\u001b[0m     x,\n\u001b[0;32m    167\u001b[0m     incremental_state\u001b[38;5;241m=\u001b[39mincremental_state,\n\u001b[0;32m    168\u001b[0m     rel_pos\u001b[38;5;241m=\u001b[39mretention_rel_pos,\n\u001b[0;32m    169\u001b[0m     chunkwise_recurrent\u001b[38;5;241m=\u001b[39mchunkwise_recurrent,\n\u001b[0;32m    170\u001b[0m )\n\u001b[0;32m    171\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout_module(x)\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torchscale\\component\\multiscale_retention.py:194\u001b[0m, in \u001b[0;36mMultiScaleRetention.forward\u001b[1;34m(self, x, rel_pos, chunkwise_recurrent, incremental_state)\u001b[0m\n\u001b[0;32m    192\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_recurrent_forward(qr, kr, v, inner_mask)\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 194\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel_forward(qr, kr, v, inner_mask)\n\u001b[0;32m    196\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroup_norm(output)\u001b[38;5;241m.\u001b[39mreshape(bsz, tgt_len, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads)\n\u001b[0;32m    198\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgate_fn(g) \u001b[38;5;241m*\u001b[39m output\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torchscale\\component\\multiscale_retention.py:76\u001b[0m, in \u001b[0;36mMultiScaleRetention.parallel_forward\u001b[1;34m(self, qr, kr, v, mask)\u001b[0m\n\u001b[0;32m     73\u001b[0m     nn\u001b[38;5;241m.\u001b[39minit\u001b[38;5;241m.\u001b[39mxavier_uniform_(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg_proj\u001b[38;5;241m.\u001b[39mweight, gain\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2.5\u001b[39m)\n\u001b[0;32m     74\u001b[0m     nn\u001b[38;5;241m.\u001b[39minit\u001b[38;5;241m.\u001b[39mxavier_uniform_(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_proj\u001b[38;5;241m.\u001b[39mweight)\n\u001b[1;32m---> 76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparallel_forward\u001b[39m(\u001b[38;5;28mself\u001b[39m, qr, kr, v, mask):\n\u001b[0;32m     77\u001b[0m     bsz, tgt_len, embed_dim \u001b[38;5;241m=\u001b[39m v\u001b[38;5;241m.\u001b[39msize()\n\u001b[0;32m     79\u001b[0m     vr \u001b[38;5;241m=\u001b[39m v\u001b[38;5;241m.\u001b[39mview(bsz, tgt_len, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_start_time = time.perf_counter()\n",
    "for epoch in range(max_epochs):\n",
    "    stats = {'epoch': epoch + 1, 'total': max_epochs}\n",
    "    epoch_start_time = time.perf_counter()\n",
    "\n",
    "    # Every epoch runs training on train set, followed by eval on test set\n",
    "    for phase in ('train', 'test'):\n",
    "        is_training = phase == 'train'\n",
    "        ncf_retnet.train(is_training)\n",
    "        running_loss = 0.0\n",
    "        #running_loss_2 = 0.0\n",
    "        n_batches = 0\n",
    "        total_batches = len(datasets[phase][0]) // batch_size\n",
    "        # Iterate on train/test datasets in batches\n",
    "        for x_batch, y_batch in  tqdm(DatasetBatchIterator(datasets[phase][0], datasets[phase][1], batch_size=batch_size, shuffle=is_training), desc=f'{phase} phase', total=total_batches):\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            \n",
    "            # We zero out the loss gradient, since PyTorch by default accumulates gradients  \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # We need to compute gradients only during training\n",
    "            with torch.set_grad_enabled(is_training):\n",
    "                \n",
    "                outputs = ncf_retnet(x_batch[:, 0], x_batch[:, 1], )\n",
    "                loss = loss_criterion(outputs, y_batch)\n",
    "                #loss_2 = loss_criterion_2(outputs, y_batch)\n",
    "                if is_training:\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            #running_loss_2 += loss_2.item()\n",
    "        \n",
    "        # Compute overall epoch loss and update history tracker\n",
    "        epoch_loss = running_loss / len(datasets[phase][0])\n",
    "        stats[phase] = epoch_loss\n",
    "        #epoch_loss_2 = running_loss_2 / len(datasets[phase][0])\n",
    "                \n",
    "        history.append(stats)\n",
    "        \n",
    "\n",
    "        # Handle early stopping\n",
    "        if phase == 'test':\n",
    "            stats['time'] = time.perf_counter() - epoch_start_time\n",
    "            print('Epoch [{epoch:03d}/{total:03d}][Time:{time:.2f} sec] Train Loss: {train:.4f} / Validation Loss: {test:.4f}'.format(**stats))\n",
    "            if epoch_loss < min_loss:\n",
    "                min_loss = epoch_loss\n",
    "                min_loss_model_weights = copy.deepcopy(ncf_retnet.state_dict())\n",
    "                no_loss_reduction_epoch_counter = 0\n",
    "                min_epoch_number = epoch + 1\n",
    "            else:\n",
    "                no_loss_reduction_epoch_counter += 1\n",
    "    if no_loss_reduction_epoch_counter >= early_stop_epoch_threshold:\n",
    "        print(f'Early stopping applied. Minimal epoch: {min_epoch_number}')\n",
    "        break\n",
    "\n",
    "print(f'Training completion duration: {(time.perf_counter() - training_start_time):.2f} sec. Validation Loss: {min_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b46bf7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
